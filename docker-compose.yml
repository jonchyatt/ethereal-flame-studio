# Ethereal Flame Studio - Docker Compose Configuration
#
# Provides GPU-accelerated headless rendering environment with queue infrastructure.
#
# Usage:
#   docker-compose up -d redis         # Start Redis for job queue
#   docker-compose up -d whisper       # Start Whisper transcription service
#   docker-compose up -d               # Start all services
#
# Phase 3 + Phase 4 services

version: '3.8'

services:
  # Redis for BullMQ job queue
  redis:
    image: redis:7-alpine
    container_name: ethereal-redis
    # CRITICAL: noeviction prevents Redis from evicting BullMQ job data
    command: redis-server --maxmemory-policy noeviction --appendonly yes
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Whisper transcription service (Phase 4)
  whisper:
    build:
      context: ./whisper-service
      dockerfile: Dockerfile
    container_name: ethereal-whisper
    ports:
      - "8001:8001"
    volumes:
      - ./data/audio:/audio:ro  # Read-only access to audio files
      - whisper-cache:/root/.cache/huggingface  # Cache model downloads
    environment:
      - WHISPER_MODEL=${WHISPER_MODEL:-large-v3}
      - WHISPER_DEVICE=cuda
      - WHISPER_COMPUTE_TYPE=float16
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      start_period: 120s  # Model loading can take time
      retries: 3

  # Headless render server (Phase 3)
  render-server:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: ethereal-render-server
    restart: unless-stopped
    depends_on:
      redis:
        condition: service_healthy

    # Mount job and output directories
    volumes:
      - ./jobs:/app/jobs
      - ./output:/app/output
      - ./data:/app/data
      # Mount audio files directory (optional, for accessing source audio)
      - ./audio:/app/audio:ro

    # Environment variables
    environment:
      - NODE_ENV=production
      - JOBS_DIR=/app/jobs
      - OUTPUT_DIR=/app/output
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - WHISPER_SERVICE_URL=http://whisper:8001

    # GPU support (NVIDIA)
    # Uncomment if you have NVIDIA GPU and nvidia-docker installed
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]

    # Resource limits
    deploy:
      resources:
        limits:
          memory: 8G
        reservations:
          memory: 4G

    # Logging
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

    # Health check inherited from Dockerfile

  # Optional: Web UI for job submission
  web-ui:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: ethereal-web-ui
    command: ["npm", "start"]
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - WHISPER_SERVICE_URL=http://whisper:8001
    depends_on:
      redis:
        condition: service_healthy
      render-server:
        condition: service_started
    restart: unless-stopped
    profiles:
      - with-ui

volumes:
  redis-data:
  whisper-cache:
