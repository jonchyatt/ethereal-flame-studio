# Ethereal Flame Studio - Docker Compose Configuration
#
# Provides GPU-accelerated headless rendering environment with queue infrastructure,
# workflow automation via n8n, and secure remote access via Cloudflare Tunnel.
#
# Usage:
#   docker-compose up -d redis         # Start Redis for job queue
#   docker-compose up -d whisper       # Start Whisper transcription service
#   docker-compose up -d n8n           # Start n8n workflow automation
#   docker-compose up -d cloudflared   # Start Cloudflare Tunnel for remote access
#   docker-compose up -d               # Start all services
#
# Phase 3 + Phase 4 + Phase 5 services

services:
  # Cloudflare Tunnel for secure remote access (Phase 5)
  # Enables access to n8n and render server from anywhere without exposing ports
  cloudflared:
    image: cloudflare/cloudflared:latest
    container_name: ethereal-cloudflared
    restart: unless-stopped
    command: tunnel run
    environment:
      - TUNNEL_TOKEN=${CLOUDFLARE_TUNNEL_TOKEN}
    networks:
      - ethereal-network
    depends_on:
      - n8n
    profiles:
      - remote-access

  # n8n Workflow Automation (Phase 5)
  # Self-hosted for YouTube OAuth support
  n8n:
    image: docker.n8n.io/n8nio/n8n
    container_name: ethereal-n8n
    restart: unless-stopped
    ports:
      - "5678:5678"
    environment:
      - N8N_HOST=${N8N_HOST:-localhost}
      - N8N_PORT=5678
      - N8N_PROTOCOL=${N8N_PROTOCOL:-http}
      - WEBHOOK_URL=${N8N_WEBHOOK_URL:-http://localhost:5678/}
      - N8N_BASIC_AUTH_ACTIVE=${N8N_BASIC_AUTH_ACTIVE:-true}
      - N8N_BASIC_AUTH_USER=${N8N_USER:-admin}
      - N8N_BASIC_AUTH_PASSWORD=${N8N_PASSWORD:-changeme}
      - GENERIC_TIMEZONE=${TZ:-America/Los_Angeles}
      - N8N_PAYLOAD_SIZE_MAX=100
    volumes:
      - n8n_data:/home/node/.n8n
      - ${RENDER_OUTPUT_DIR:-./output}:/renders:ro
    networks:
      - ethereal-network
    profiles:
      - automation

  # Redis for BullMQ job queue
  redis:
    image: redis:7-alpine
    container_name: ethereal-redis
    # CRITICAL: noeviction prevents Redis from evicting BullMQ job data
    command: redis-server --maxmemory-policy noeviction --appendonly yes
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    networks:
      - ethereal-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Whisper transcription service (Phase 4)
  whisper:
    build:
      context: ./whisper-service
      dockerfile: Dockerfile
    container_name: ethereal-whisper
    ports:
      - "8001:8001"
    volumes:
      - ./data/audio:/audio:ro  # Read-only access to audio files
      - whisper-cache:/root/.cache/huggingface  # Cache model downloads
    environment:
      - WHISPER_MODEL=${WHISPER_MODEL:-large-v3}
      - WHISPER_DEVICE=cuda
      - WHISPER_COMPUTE_TYPE=float16
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      start_period: 120s  # Model loading can take time
      retries: 3

  # Headless render server (Phase 3)
  render-server:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: ethereal-render-server
    restart: unless-stopped
    depends_on:
      redis:
        condition: service_healthy

    # Mount job and output directories
    volumes:
      - ./jobs:/app/jobs
      - ./output:/app/output
      - ./data:/app/data
      # Mount audio files directory (optional, for accessing source audio)
      - ./audio:/app/audio:ro

    # Environment variables
    environment:
      - NODE_ENV=production
      - JOBS_DIR=/app/jobs
      - OUTPUT_DIR=/app/output
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - WHISPER_SERVICE_URL=http://whisper:8001
      - N8N_WEBHOOK_RENDER_URL=${N8N_WEBHOOK_RENDER_URL:-}
      - N8N_WEBHOOK_SECRET=${N8N_WEBHOOK_SECRET:-}

    networks:
      - ethereal-network

    # GPU support (NVIDIA)
    # Uncomment if you have NVIDIA GPU and nvidia-docker installed
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]

    # Resource limits
    deploy:
      resources:
        limits:
          memory: 8G
        reservations:
          memory: 4G

    # Logging
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

    # Health check inherited from Dockerfile

  # Optional: Web UI for job submission
  web-ui:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: ethereal-web-ui
    command: ["npm", "start"]
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - WHISPER_SERVICE_URL=http://whisper:8001
    networks:
      - ethereal-network
    depends_on:
      redis:
        condition: service_healthy
      render-server:
        condition: service_started
    restart: unless-stopped
    profiles:
      - with-ui

networks:
  ethereal-network:
    driver: bridge

volumes:
  redis-data:
  whisper-cache:
  n8n_data:
