---
phase: 04-automation
plan: 05
type: execute
wave: 3
depends_on: ["04-03", "04-04"]
files_modified:
  - src/lib/queue/transcriptionWorker.ts
  - src/lib/queue/renderWorker.ts
  - scripts/start-worker.ts
autonomous: true
user_setup: []

must_haves:
  truths:
    - "Completed renders automatically get transcribed"
    - "Transcription stored in SQLite whisper_description field"
    - "Transcription runs after render completes (not during)"
  artifacts:
    - path: "src/lib/queue/transcriptionWorker.ts"
      provides: "Worker for post-render transcription"
      exports: ["startTranscriptionWorker"]
  key_links:
    - from: "src/lib/queue/renderWorker.ts"
      to: "transcription queue"
      via: "job creation on complete"
      pattern: "transcriptionQueue.add"
    - from: "src/lib/queue/transcriptionWorker.ts"
      to: "src/lib/services/whisperClient.ts"
      via: "HTTP call"
      pattern: "transcribeFile"
---

<objective>
Integrate Whisper transcription into the render pipeline.

Purpose: Automatically transcribe audio after renders complete to generate video descriptions. This runs as a separate queue to not block rendering.

Output: Transcription queue and worker that processes completed renders.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/04-automation/04-RESEARCH.md
@.planning/phases/04-automation/04-03-SUMMARY.md (when exists)
@.planning/phases/04-automation/04-04-SUMMARY.md (when exists)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create transcription queue and worker</name>
  <files>src/lib/queue/transcriptionQueue.ts, src/lib/queue/transcriptionWorker.ts</files>
  <action>
Create `src/lib/queue/transcriptionQueue.ts`:

```typescript
import { Queue } from 'bullmq';
import { redisConnection } from './connection';

export interface TranscriptionJobData {
  renderDbId: string;
  audioPath: string;
  audioName: string;
}

export const transcriptionQueue = new Queue<TranscriptionJobData>('transcription-queue', {
  connection: redisConnection,
  defaultJobOptions: {
    removeOnComplete: { count: 100 },
    removeOnFail: { count: 100 },
    attempts: 2, // Transcription is less critical, fewer retries
    backoff: {
      type: 'fixed',
      delay: 30000, // 30s between retries
    },
  },
});

export async function addTranscriptionJob(data: TranscriptionJobData): Promise<string> {
  const job = await transcriptionQueue.add('transcribe', data, {
    jobId: `transcribe-${data.renderDbId}`,
  });
  return job.id || '';
}

export async function closeTranscriptionQueue(): Promise<void> {
  await transcriptionQueue.close();
}
```

Create `src/lib/queue/transcriptionWorker.ts`:

```typescript
import { Worker, Job } from 'bullmq';
import { redisConnection } from './connection';
import { TranscriptionJobData } from './transcriptionQueue';
import { transcribeFile, formatVideoDescription, checkWhisperHealth } from '@/lib/services/whisperClient';
import { updateRender, getRenderById } from '@/lib/db';

let worker: Worker<TranscriptionJobData> | null = null;

async function processTranscriptionJob(job: Job<TranscriptionJobData>): Promise<void> {
  const { renderDbId, audioPath, audioName } = job.data;

  console.log(`[Transcription] Processing: ${audioName}`);

  // Check Whisper service health
  const healthy = await checkWhisperHealth();
  if (!healthy) {
    throw new Error('Whisper service unavailable');
  }

  try {
    await job.updateProgress(10);

    // Transcribe the audio
    const result = await transcribeFile(audioPath);

    await job.updateProgress(80);

    // Format as video description
    const description = formatVideoDescription(result, audioName);

    // Update database
    updateRender(renderDbId, {
      whisper_description: description,
      duration_seconds: result.durationSeconds,
    });

    await job.updateProgress(100);

    console.log(`[Transcription] Complete: ${audioName} (${result.language}, ${Math.round(result.durationSeconds)}s)`);

  } catch (error) {
    const message = error instanceof Error ? error.message : String(error);
    console.error(`[Transcription] Failed: ${audioName} - ${message}`);

    // Don't update render status - transcription failure shouldn't mark render as failed
    // Just log and move on
    throw error;
  }
}

export function startTranscriptionWorker(): Worker<TranscriptionJobData> {
  if (worker) {
    console.warn('[Transcription] Worker already running');
    return worker;
  }

  worker = new Worker<TranscriptionJobData>('transcription-queue', processTranscriptionJob, {
    connection: redisConnection,
    concurrency: 1, // One transcription at a time (GPU shared with render)
    lockDuration: 600000, // 10 minutes (long audio files)
  });

  worker.on('completed', (job) => {
    console.log(`[Transcription] Job ${job.id} completed`);
  });

  worker.on('failed', (job, err) => {
    console.error(`[Transcription] Job ${job?.id} failed:`, err.message);
  });

  console.log('[Transcription] Worker started');
  return worker;
}

export async function stopTranscriptionWorker(): Promise<void> {
  if (worker) {
    await worker.close();
    worker = null;
    console.log('[Transcription] Worker stopped');
  }
}
```
  </action>
  <verify>
```typescript
import { addTranscriptionJob } from './transcriptionQueue';
import { startTranscriptionWorker, stopTranscriptionWorker } from './transcriptionWorker';

// Start worker
startTranscriptionWorker();

// Add test job (requires existing render in DB and Whisper service)
await addTranscriptionJob({
  renderDbId: 'test-render-id',
  audioPath: '/path/to/test.mp3',
  audioName: 'Test Audio',
});

// Watch logs for transcription progress
```
  </verify>
  <done>
Transcription queue and worker process audio files, store descriptions in database.
  </done>
</task>

<task type="auto">
  <name>Task 2: Wire transcription to render completion</name>
  <files>src/lib/queue/renderWorker.ts</files>
  <action>
Update `src/lib/queue/renderWorker.ts` to add transcription job after render completes:

Add import at top:
```typescript
import { addTranscriptionJob } from './transcriptionQueue';
```

In `processRenderJob`, after successful post-processing (after `postProcessRender`), add:

```typescript
// Queue transcription job (runs asynchronously, doesn't block)
try {
  await addTranscriptionJob({
    renderDbId,
    audioPath: audioFile.path,
    audioName: audioFile.originalName.replace(/\.[^/.]+$/, ''),
  });
  console.log(`[Worker] Queued transcription for: ${audioFile.originalName}`);
} catch (transcriptionError) {
  // Log but don't fail the render job if transcription queue fails
  console.warn(`[Worker] Failed to queue transcription:`, transcriptionError);
}
```

This ensures:
- Transcription is queued after render completes
- Transcription failure doesn't affect render success
- Transcription runs in parallel with next render job
  </action>
  <verify>
End-to-end test:
1. Start both workers (`npm run worker`)
2. Add a batch job
3. Watch logs - render completes, then transcription starts
4. Check database - whisper_description populated after transcription
  </verify>
  <done>
Render completion automatically queues transcription, description stored in database.
  </done>
</task>

<task type="auto">
  <name>Task 3: Update worker CLI to run both workers</name>
  <files>scripts/start-worker.ts</files>
  <action>
Update `scripts/start-worker.ts` to run both render and transcription workers:

```typescript
#!/usr/bin/env node
import { startWorker, stopWorker } from '../src/lib/queue/renderWorker';
import { startTranscriptionWorker, stopTranscriptionWorker } from '../src/lib/queue/transcriptionWorker';
import { closeQueue } from '../src/lib/queue/renderQueue';
import { closeTranscriptionQueue } from '../src/lib/queue/transcriptionQueue';

console.log('Starting Ethereal Flame workers...');

// Parse arguments
const args = process.argv.slice(2);
const runRender = args.length === 0 || args.includes('--render');
const runTranscribe = args.length === 0 || args.includes('--transcribe');

// Graceful shutdown
let isShuttingDown = false;
const shutdown = async () => {
  if (isShuttingDown) return;
  isShuttingDown = true;

  console.log('\nShutting down workers...');

  if (runRender) {
    await stopWorker();
    await closeQueue();
  }
  if (runTranscribe) {
    await stopTranscriptionWorker();
    await closeTranscriptionQueue();
  }

  console.log('Workers stopped');
  process.exit(0);
};

process.on('SIGTERM', shutdown);
process.on('SIGINT', shutdown);

// Start workers
if (runRender) {
  startWorker();
}
if (runTranscribe) {
  startTranscriptionWorker();
}

console.log(`Workers running: render=${runRender}, transcribe=${runTranscribe}`);
console.log('Press Ctrl+C to stop.');
```

Update `package.json` scripts:
```json
{
  "scripts": {
    "worker": "ts-node scripts/start-worker.ts",
    "worker:render": "ts-node scripts/start-worker.ts --render",
    "worker:transcribe": "ts-node scripts/start-worker.ts --transcribe"
  }
}
```

This allows:
- `npm run worker` - runs both workers
- `npm run worker:render` - render only
- `npm run worker:transcribe` - transcription only
  </action>
  <verify>
```bash
# Run all workers
npm run worker
# Should show:
# [Worker] Started, waiting for jobs...
# [Transcription] Worker started
# Workers running: render=true, transcribe=true

# Ctrl+C should stop both cleanly
```
  </verify>
  <done>
Worker CLI runs both render and transcription workers, supports selective startup.
  </done>
</task>

</tasks>

<verification>
1. `npm run worker` starts both render and transcription workers
2. Completed renders automatically queue transcription jobs
3. Transcription results stored in SQLite whisper_description field
4. Transcription failure doesn't affect render job status
5. Workers shut down gracefully on Ctrl+C
</verification>

<success_criteria>
- Render completion triggers transcription queue
- Transcription worker calls Whisper service
- Video descriptions stored in database
- Transcription runs asynchronously (doesn't block rendering)
- Worker CLI supports running both or individual workers
</success_criteria>

<output>
After completion, create `.planning/phases/04-automation/04-05-SUMMARY.md`
</output>
