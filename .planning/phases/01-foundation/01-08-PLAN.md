---
phase: 01-foundation
plan: 08
type: execute
wave: 5
depends_on: ["01-02", "01-03", "01-04", "01-05", "01-06", "01-07"]
files_modified:
  - src/components/canvas/ParticleSystem.tsx
  - src/components/canvas/ParticleLayer.tsx
  - src/components/canvas/StarNestSkybox.tsx
  - src/app/page.tsx
autonomous: false

must_haves:
  truths:
    - "Audio FFT drives particle size, position, and intensity"
    - "Bass affects inner layer more than outer layer"
    - "Treble affects haze/halo layers"
    - "Skybox rotation speed responds to audio"
    - "Beat detection causes pulse effect"
  artifacts:
    - path: "src/components/canvas/ParticleSystem.tsx"
      provides: "Wired audio-reactive particle system"
      contains: "useAudioStore"
  key_links:
    - from: "src/components/canvas/ParticleSystem.tsx"
      to: "src/lib/stores/audioStore.ts"
      via: "useAudioStore subscription"
      pattern: "useAudioStore.*getState"
    - from: "src/components/canvas/ParticleLayer.tsx"
      to: "useFrame"
      via: "Audio levels applied per frame"
      pattern: "audioReactivity.*bandAmplitude"
---

<objective>
Wire audio analyzer to particle system and skybox for full audio-reactive experience.

Purpose: Connect all the pieces built in previous plans. Audio levels drive visual properties in real-time, creating the core audio-reactive experience. This is the integration that makes the product work.

Output: Full audio-reactive visual experience where uploading music creates synchronized visuals.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/01-foundation/01-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Wire audio store to ParticleSystem and layers</name>
  <files>
    - src/components/canvas/ParticleSystem.tsx
    - src/components/canvas/ParticleLayer.tsx
  </files>
  <action>
1. Update ParticleSystem to read from audio store:
   ```tsx
   import { useAudioStore } from '@/lib/stores/audioStore';

   export function ParticleSystem() {
     const { layers, intensity } = useVisualStore();
     const colorPalette = useVisualStore(s => s.modeConfigs[s.currentMode].colorPalette);

     // Global hue ref for rainbow cycling
     const globalHueRef = useRef(0);

     // Read audio state in animation loop (not via subscription to avoid re-renders)
     useFrame(() => {
       const { bass, mids, treble, amplitude, isBeat, currentScale } = useAudioStore.getState();

       // Update global hue based on audio
       globalHueRef.current = (globalHueRef.current + 0.003) % 1.0;
       if (amplitude > 0.2) {
         globalHueRef.current = (globalHueRef.current + amplitude * 0.015) % 1.0;
       }

       // If beat, jump hue
       if (isBeat) {
         globalHueRef.current = (globalHueRef.current + 0.12) % 1.0;
       }
     });

     // Get current audio values for passing to layers (need to use getState pattern)
     // Layers will also read directly in their useFrame

     return (
       <group>
         {layers.filter(l => l.enabled).map(config => (
           <ParticleLayer
             key={config.id}
             config={config}
             intensity={intensity}
             globalHueRef={globalHueRef}
             colorPalette={colorPalette}
           />
         ))}
       </group>
     );
   }
   ```

2. Update ParticleLayer to apply audio reactivity in useFrame:
   ```tsx
   useFrame(({ clock }) => {
     // Read audio state directly (no subscription)
     const { bass, mids, treble, amplitude, isBeat, currentScale } = useAudioStore.getState();

     // Get amplitude for this layer's frequency band
     let bandAmplitude = 0;
     switch (config.frequencyBand) {
       case 'bass': bandAmplitude = bass; break;
       case 'mids': bandAmplitude = mids; break;
       case 'treble': bandAmplitude = treble; break;
       case 'all': bandAmplitude = amplitude; break;
     }

     // Apply audio reactivity to scale/position
     const reactivity = config.audioReactivity;
     const audioScale = 1.0 + bandAmplitude * reactivity * 0.8;
     const beatPulse = isBeat ? 1.2 : 1.0;

     // In the particle loop:
     for (let i = 0; i < particleCount; i++) {
       // ... existing age/lifetime logic ...

       // Apply audio-reactive scale to position
       const totalScale = audioScale * beatPulse;
       posAttr.setXYZ(
         i,
         (bx + vx * age) * totalScale,
         (by + vy * age) * totalScale,
         (bz + vz * age) * totalScale
       );

       // Apply audio to particle size
       const audioSizeMult = 1.0 + bandAmplitude * reactivity * 0.5;
       sizeAttr.setX(i, state.baseSizes[i] * sizeMult * audioSizeMult);
     }
   });
   ```

3. Apply smooth lerp transitions (VIS-12):
   Use refs to track previous values and lerp:
   ```tsx
   const prevScaleRef = useRef(1.0);
   const prevBandRef = useRef(0);

   useFrame((_, delta) => {
     // Smooth lerp for scale
     const lerpFactor = Math.min(1, delta * 8);
     prevScaleRef.current += (targetScale - prevScaleRef.current) * lerpFactor;
     prevBandRef.current += (bandAmplitude - prevBandRef.current) * lerpFactor;

     // Use smoothed values
     const smoothScale = prevScaleRef.current;
     const smoothBand = prevBandRef.current;
   });
   ```
  </action>
  <verify>
    Play audio - particles should pulse to the beat
    Bass affects inner layer more than outer
    Size changes smoothly (no jarring transitions)
  </verify>
  <done>
    Audio store wired to ParticleSystem
    Frequency bands drive respective layers (VIS-08, VIS-09)
    Beat detection causes pulse effect (AUD-04)
    Smooth lerp transitions (VIS-12)
  </done>
</task>

<task type="auto">
  <name>Task 2: Wire audio to skybox rotation and finalize integration</name>
  <files>
    - src/components/canvas/StarNestSkybox.tsx
    - src/app/page.tsx
  </files>
  <action>
1. Update StarNestSkybox to modulate rotation with audio:
   ```tsx
   useFrame((_, delta) => {
     if (!materialRef.current) return;

     // Read audio
     const { amplitude, bass } = useAudioStore.getState();

     // Base rotation from preset
     const baseSpeed = preset.rotation[3];

     // Audio-modulated rotation: faster when louder
     const audioModulation = 1.0 + amplitude * 0.5 + bass * 0.3;
     const effectiveSpeed = baseSpeed * audioModulation;

     // Update time uniform
     timeRef.current += delta * effectiveSpeed;
     materialRef.current.uniforms.uTime.value = timeRef.current;
   });
   ```

2. Ensure proper render order in page.tsx:
   ```tsx
   <Canvas ...>
     {/* Skybox first (background) */}
     <StarNestSkybox />

     {/* Particles on top */}
     <ParticleSystem />

     {/* Camera controls */}
     <OrbitControls ... />
   </Canvas>
   ```

3. Verify the audio update loop is running:
   In AudioControls, ensure the animation loop updates the analyzer:
   ```tsx
   useEffect(() => {
     if (!isPlaying) return;

     let lastTime = performance.now();
     let rafId: number;

     function loop() {
       const now = performance.now();
       const delta = (now - lastTime) / 1000;
       lastTime = now;

       // Update audio analyzer
       audioAnalyzer.update(delta);

       // Update store with new values
       setLevels({
         amplitude: audioAnalyzer.amplitude,
         bass: audioAnalyzer.bass,
         mids: audioAnalyzer.mid,
         treble: audioAnalyzer.high,
       });
       setBeat(audioAnalyzer.isBeat, audioAnalyzer.currentScale);

       rafId = requestAnimationFrame(loop);
     }

     rafId = requestAnimationFrame(loop);
     return () => cancelAnimationFrame(rafId);
   }, [isPlaying]);
   ```

4. Final integration checklist:
   - AudioControls updates audioStore
   - ParticleSystem reads audioStore in useFrame
   - ParticleLayer applies band amplitude per config
   - StarNestSkybox modulates rotation with amplitude
   - Beat detection triggers pulse effects
   - All transitions are smooth (lerped)
  </action>
  <verify>
    Full integration works end-to-end
    Upload audio -> play -> visuals react
    Skybox rotates faster during loud sections
    Beat pulses visible on bass hits
  </verify>
  <done>
    Skybox rotation responds to audio (VIS-07)
    Full audio-visual integration complete
    All components wired and working together
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
Complete Phase 1 audio-reactive visual experience:
- Audio file upload and FFT analysis
- Dual-layer particle system with size-over-lifetime curve
- Star Nest procedural skybox
- Ethereal Mist and Ethereal Flame modes
- Mobile-friendly control panel
- Full audio-visual integration
  </what-built>
  <how-to-verify>
1. Open http://localhost:3000 on your phone (or use browser mobile emulation)
2. Upload a music file with strong bass (EDM, hip-hop work well)
3. Click play - verify audio plays through speakers
4. Observe particles:
   - Do they pulse on bass hits?
   - Do they expand/contract with amplitude?
   - Is the size-over-lifetime curve visible (bloom then fade)?
5. Switch to "Ethereal Mist" mode:
   - Are particles softer and slower?
   - Are colors more pastel?
6. Switch to "Ethereal Flame" mode:
   - Do particles drift upward?
   - Are colors warm (orange/red/yellow)?
7. Change skybox preset:
   - Does the background change?
   - Does it rotate subtly?
8. Test on mobile (or Chrome DevTools device mode):
   - Are controls usable?
   - Is performance acceptable?

Expected: Visuals clearly react to audio, mode switching changes the aesthetic, mobile UI works.
  </how-to-verify>
  <resume-signal>Type "approved" if Phase 1 works as expected, or describe issues to fix</resume-signal>
</task>

</tasks>

<verification>
1. Upload audio file with bass
2. Play audio - particles should pulse to beat
3. Verify bass affects inner layer (config.frequencyBand: 'bass')
4. Verify mids affect outer haze layers
5. Verify skybox rotates faster during loud parts
6. Verify beat detection causes visible pulse
7. Verify smooth transitions (no jarring jumps)
8. Test mode switching while audio plays
9. Test on mobile device or emulation
</verification>

<success_criteria>
Phase 1 complete when ALL requirements satisfied:

Audio requirements:
- [x] AUD-01: Audio file upload (MP3, WAV, OGG)
- [x] AUD-02: Real-time FFT analysis for preview
- [x] AUD-04: Beat detection for pulse effects

Visual requirements:
- [x] VIS-01: Real-time WebGL preview of visuals in browser
- [x] VIS-02: Ethereal Mist mode - soft cloud-like particle effect
- [x] VIS-03: Ethereal Flame mode - organic upward drift, warm colors
- [x] VIS-04: Particle lifetime system - spawn/live/die cycle
- [x] VIS-05: Dual-layer particle system - inner glow + outer halo
- [x] VIS-05b: Scalable particle count (2000 default, up to 50,000+)
- [x] VIS-06: Star Nest skybox - procedural volumetric background
- [x] VIS-07: Automatic skybox rotation during playback
- [x] VIS-08: Audio FFT analysis driving particle behavior
- [x] VIS-09: Frequency band separation (bass, mids, treble)
- [x] VIS-10: Size-over-lifetime curve (Unity reference implementation)
- [x] VIS-11: Threshold-crossing beat detection with minimum interval
- [x] VIS-12: Smooth lerp transitions for all reactive properties

Infrastructure:
- [x] INF-01: Mobile-friendly web UI

All 17 requirements covered. Phase 1 Foundation complete.
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation/01-08-SUMMARY.md`
</output>
