---
phase: 14-api-worker-processing-pipeline
plan: 02
type: execute
wave: 2
depends_on: [14-01]
files_modified:
  - worker/process-job.ts
  - worker/pipelines/ingest.ts
  - worker/pipelines/preview.ts
  - worker/pipelines/save.ts
  - worker/tsconfig.json
autonomous: true
requirements: [WORK-02, WORK-03, SEC-02]

must_haves:
  truths:
    - "Worker ingests audio from YouTube URLs by spawning yt-dlp, writing result to R2"
    - "Worker ingests audio from direct URLs by downloading and writing to R2"
    - "Worker ingests audio from R2 presigned uploads (file uploads) by reading the uploaded file from storage"
    - "Worker executes edit preview recipes using ffmpeg filter_complex and writes MP3 result to R2"
    - "Worker executes edit save recipes using ffmpeg filter_complex with 2-pass loudnorm and writes result to R2"
    - "Cloud ingest rejects files over 100MB and audio over 30 minutes duration"
    - "Worker reports progress and stage updates via JobStore throughout each pipeline"
  artifacts:
    - path: "worker/pipelines/ingest.ts"
      provides: "Ingest pipeline for YouTube, URL, and file upload sources"
      contains: "extractYouTubeAudio"
    - path: "worker/pipelines/preview.ts"
      provides: "Edit preview pipeline with ffmpeg render"
      contains: "renderRecipe"
    - path: "worker/pipelines/save.ts"
      provides: "Edit save pipeline with ffmpeg render and 2-pass loudnorm"
      contains: "renderRecipe"
    - path: "worker/process-job.ts"
      provides: "Job dispatcher routing to pipeline functions"
      contains: "runIngestPipeline"
  key_links:
    - from: "worker/process-job.ts"
      to: "worker/pipelines/ingest.ts"
      via: "import and dispatch by job.type"
      pattern: "runIngestPipeline"
    - from: "worker/pipelines/ingest.ts"
      to: "src/lib/storage/index.ts"
      via: "getStorageAdapter() for reading uploads and writing results"
      pattern: "getStorageAdapter"
    - from: "worker/pipelines/preview.ts"
      to: "src/lib/audio-prep/audioRenderer.ts"
      via: "renderRecipe() for ffmpeg filter_complex execution"
      pattern: "renderRecipe"
---

<objective>
Wire actual ingest, preview, and save processing pipelines into the worker's process-job dispatcher, replacing the Phase 13 placeholder logic.

Purpose: The worker infrastructure (poll loop, heartbeat, cancellation, reaper) was built in Phase 13 with placeholder pipeline functions. This plan extracts the actual processing logic from the old API routes into worker-callable pipeline modules that read from and write to the storage adapter, enabling cloud-native audio processing.

Output: Three pipeline modules (ingest, preview, save) in `worker/pipelines/` that the worker dispatches by job type. Each pipeline reads source data from storage, processes with ffmpeg/yt-dlp, writes results to storage, and reports progress via JobStore.
</objective>

<execution_context>
@C:/Users/jonch/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/jonch/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/14-api-worker-processing-pipeline/14-01-PLAN.md
@.planning/phases/13-job-state-worker-infra/13-03-SUMMARY.md
@worker/process-job.ts
@worker/index.ts
@worker/tsconfig.json
@src/lib/jobs/types.ts
@src/lib/storage/types.ts
@src/lib/storage/index.ts
@src/app/api/audio/ingest/route.ts
@src/app/api/audio/edit/preview/route.ts
@src/app/api/audio/edit/save/route.ts
@src/lib/audio-prep/AudioAssetService.ts
@src/lib/audio-prep/audioRenderer.ts
@src/lib/audio-prep/filterComplexBuilder.ts
@src/lib/audio-prep/ffprobe.ts
@src/lib/audio-prep/peaksGenerator.ts
@src/lib/audio-prep/ytdlp.ts
@src/lib/audio-prep/urlSecurity.ts
@src/lib/audio-prep/types.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create ingest pipeline module for the worker</name>
  <files>
    worker/pipelines/ingest.ts
    worker/tsconfig.json
  </files>
  <action>
Create `worker/pipelines/ingest.ts` that handles all ingest source types. This extracts the processing logic from the old `processIngest` function in the ingest API route, adapted for worker context (async JobStore, storage adapter, child process ref for cancellation).

The module exports a single function:
```typescript
export async function runIngestPipeline(
  store: JobStore,
  job: AudioPrepJob,
  childRef: { current: ChildProcess | null },
): Promise<void>
```

Pipeline logic by source type (read from `job.metadata.sourceType`):

1. **YouTube** (`job.metadata.sourceType === 'youtube'`):
   - Read `job.metadata.url` and `job.metadata.rightsAttested`
   - Use `extractYouTubeAudio()` from `../../src/lib/audio-prep/ytdlp` to download audio to a temp directory
   - Set `childRef.current` to the yt-dlp child process for cancellation support
   - Report progress: stage='downloading', progress 10-50

2. **URL** (`job.metadata.sourceType === 'url'`):
   - Read `job.metadata.url`
   - Use `validateUrl()` from `../../src/lib/audio-prep/urlSecurity` for SSRF protection
   - Download to temp file using fetch with streaming (same pattern as old route)
   - **SEC-02 enforcement:** Reject downloads exceeding 100MB (100 * 1024 * 1024 bytes)
   - Report progress: stage='downloading', progress 10-50

3. **File upload** (`job.metadata.sourceType === 'audio_file' || 'video_file'`):
   - Read `job.metadata.storageKey` (file already in storage from API route upload)
   - Download from storage to temp file via `getStorageAdapter().get()`
   - For `video_file`: extract audio via ffmpeg (spawn process, set childRef)
   - Report progress: stage='downloading', progress 10-30

After download (all types):
- **SEC-02 enforcement:** Probe audio via `probeAudio()`. Reject if duration > 30 minutes (1800 seconds).
- **SEC-02 enforcement:** Check file size. Reject if > 100MB.
- Update stage='analyzing', progress 60
- Create asset via `AudioAssetService.createAsset()` (writes original to storage)
- Update asset metadata with probed audio info
- Generate peaks via `generatePeaks()`, upload to storage
- Update stage='finalizing', progress 90-95
- Complete job with result `{ assetId, metadata }` via `store.complete()`
- Cleanup temp directory

**Config values:** Use `AudioAssetService.config.maxFileSizeMB` (100) and `config.maxDurationMinutes` (30) rather than hardcoded values.

Update `worker/tsconfig.json` to include paths for `../../src/lib/audio-prep/*` modules so the worker can import them.
  </action>
  <verify>
Run `npx tsc --noEmit -p worker/tsconfig.json` to verify the pipeline compiles. Check that the file exports `runIngestPipeline`. Verify SEC-02 enforcement by grepping for `maxFileSizeMB` and `maxDurationMinutes` checks.
  </verify>
  <done>
Worker can ingest audio from YouTube URLs, direct URLs, and file uploads. Cloud ingest enforces 100MB file size and 30-minute duration limits. Progress reported via JobStore at each stage. Child processes exposed via childRef for cancellation.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create preview and save pipeline modules, wire all pipelines into process-job dispatcher</name>
  <files>
    worker/pipelines/preview.ts
    worker/pipelines/save.ts
    worker/process-job.ts
  </files>
  <action>
1. **Create `worker/pipelines/preview.ts`:**

Export:
```typescript
export async function runPreviewPipeline(
  store: JobStore,
  job: AudioPrepJob,
  childRef: { current: ChildProcess | null },
): Promise<void>
```

Logic (extracted from old preview route):
- Read recipe from `job.metadata.recipe` and recipeHash from `job.metadata.recipeHash`
- Check preview cache: look for `assets/{recipe.assetId}/preview_{recipeHash}.mp3` in storage. If exists, complete immediately with `{ previewKey }`.
- For each unique `sourceAssetId` in `recipe.clips`:
  - Download the original audio from storage to a temp file (same temp-file pattern from old route)
  - Build `assetPaths` map of `assetId -> tempFilePath`
- Validate recipe against source durations using `validateRecipe()`
- stage='rendering', progress 30
- Call `renderRecipe()` with `{ preview: true }` option (outputs 128k MP3)
- Note: renderRecipe spawns ffmpeg internally -- the childRef is not directly available here since renderRecipe uses its own spawn. For now, pass `signal` support via AbortSignal pattern if renderRecipe supports it, or accept that cancellation kills the worker process which ffmpeg inherits.
- stage='uploading', progress 90
- Upload preview MP3 to storage at `assets/{recipe.assetId}/preview_{recipeHash}.mp3`
- Complete job with `{ previewKey: cachedKey }`
- Cleanup temp files

2. **Create `worker/pipelines/save.ts`:**

Export:
```typescript
export async function runSavePipeline(
  store: JobStore,
  job: AudioPrepJob,
  childRef: { current: ChildProcess | null },
): Promise<void>
```

Logic (extracted from old save route):
- Read recipe from `job.metadata.recipe`
- For each unique sourceAssetId: download original to temp file, build assetPaths map
- Validate recipe using `validateRecipe()`
- Remove previous `prepared.*` files from storage for the target asset
- stage='rendering', progress 20
- Call `renderRecipe()` with `{ twoPassNormalize: recipe.normalize }` (high-quality output)
- stage='uploading', progress 80
- Upload prepared file to storage at `assets/{recipe.assetId}/prepared.{ext}`
- Save recipe JSON to `assets/{recipe.assetId}/edits.json`
- Complete job with `{ assetId: recipe.assetId, preparedKey }`
- Cleanup temp files

3. **Update `worker/process-job.ts`:**

Replace the placeholder dispatch block with actual pipeline routing:

```typescript
// -- Dispatch by job type --
switch (job.type) {
  case 'ingest':
    await runIngestPipeline(store, job, childRef);
    break;
  case 'preview':
    await runPreviewPipeline(store, job, childRef);
    break;
  case 'save':
    await runSavePipeline(store, job, childRef);
    break;
  default:
    throw new Error(`Unknown job type: ${job.type}`);
}
```

Remove the placeholder `setTimeout` and placeholder `store.complete()` call. Import the three pipeline functions. Keep all existing heartbeat, cancellation detection, and error handling logic intact.
  </action>
  <verify>
Run `npx tsc --noEmit -p worker/tsconfig.json` to verify all three pipeline modules and the updated process-job compile. Grep for `placeholder` in process-job.ts to confirm placeholder code is removed. Verify all three pipeline imports exist in process-job.ts.
  </verify>
  <done>
Worker dispatches ingest, preview, and save jobs to their respective pipeline modules. Preview pipeline uses ffmpeg filter_complex with cache check. Save pipeline uses 2-pass loudnorm. All pipelines read/write via storage adapter and report progress via JobStore. Placeholder code fully removed from process-job.ts.
  </done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit -p worker/tsconfig.json` passes with zero errors
2. `grep -r "placeholder" worker/process-job.ts` returns no matches
3. `grep -r "runIngestPipeline\|runPreviewPipeline\|runSavePipeline" worker/process-job.ts` returns three matches
4. `worker/pipelines/ingest.ts`, `worker/pipelines/preview.ts`, `worker/pipelines/save.ts` all exist
5. `grep "maxFileSizeMB\|maxDurationMinutes" worker/pipelines/ingest.ts` confirms SEC-02 enforcement
</verification>

<success_criteria>
- Worker successfully ingests audio from YouTube URLs, direct URLs, and file uploads via R2
- Worker executes edit recipes (trim, split, join, fade, volume, normalize) using filter_complex pipeline
- Cloud ingest rejects files over 100MB and audio over 30 minutes duration
- Worker reports granular progress (stage + percentage) for all pipeline types
- All pipelines read source from storage and write results to storage
- TypeScript compilation passes cleanly for the worker project
</success_criteria>

<output>
After completion, create `.planning/phases/14-api-worker-processing-pipeline/14-02-SUMMARY.md`
</output>
