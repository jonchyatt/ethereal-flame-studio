---
phase: 08-memory-loading-integration
plan: 02
type: execute
wave: 2
depends_on: ["08-01"]
files_modified:
  - src/lib/jarvis/intelligence/systemPrompt.ts
  - src/lib/jarvis/voice/VoicePipeline.ts
  - src/app/api/jarvis/chat/route.ts
  - src/lib/jarvis/config.ts
autonomous: true

must_haves:
  truths:
    - "Jarvis loads memories from database at conversation start"
    - "Memories appear in system prompt sent to Claude"
    - "Feature flag can disable memory loading"
    - "Existing v1 features continue to work unchanged"
  artifacts:
    - path: "src/lib/jarvis/config.ts"
      provides: "Feature flags including ENABLE_MEMORY_LOADING"
      exports: ["jarvisConfig", "JarvisConfig"]
    - path: "src/lib/jarvis/intelligence/systemPrompt.ts"
      provides: "Enhanced buildSystemPrompt with memory context"
      exports: ["buildSystemPrompt", "SystemPromptContext"]
    - path: "src/app/api/jarvis/chat/route.ts"
      provides: "Chat route with memory loading"
      contains: "retrieveMemories"
  key_links:
    - from: "src/app/api/jarvis/chat/route.ts"
      to: "src/lib/jarvis/memory/retrieval.ts"
      via: "retrieveMemories import and call"
      pattern: "await retrieveMemories"
    - from: "src/lib/jarvis/intelligence/systemPrompt.ts"
      to: "memory context injection"
      via: "memoryContext parameter"
      pattern: "memoryContext.*formatMemoriesForPrompt"
---

<objective>
Integrate memory retrieval into the voice pipeline so Jarvis loads relevant memories at conversation start.

Purpose: Satisfy MEM-06 (load relevant memory context at session start) and MEM-07 (reference previous conversations naturally). This creates continuity across sessions.

Output: Modified system prompt builder, chat API, and feature flag for controlled rollout.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@jarvis/.planning/PROJECT.md
@jarvis/.planning/ROADMAP.md
@jarvis/.planning/phases/08-memory-loading-integration/08-CONTEXT.md
@jarvis/.planning/phases/08-memory-loading-integration/08-01-SUMMARY.md
@src/lib/jarvis/intelligence/systemPrompt.ts
@src/lib/jarvis/voice/VoicePipeline.ts
@src/app/api/jarvis/chat/route.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create feature flag configuration</name>
  <files>src/lib/jarvis/config.ts</files>
  <action>
Create `src/lib/jarvis/config.ts` with feature flags:

```typescript
/**
 * Jarvis Feature Configuration
 *
 * Centralized feature flags for controlled rollout.
 * Read from environment variables with sensible defaults.
 */

export interface JarvisConfig {
  /** Enable memory loading from database at session start */
  enableMemoryLoading: boolean;
  /** Maximum tokens to use for memory context (default 1000) */
  memoryTokenBudget: number;
  /** Maximum number of memories to load (default 10) */
  maxMemories: number;
}

/**
 * Get Jarvis configuration from environment.
 *
 * Environment variables:
 * - JARVIS_ENABLE_MEMORY: "true" to enable (default: false during rollout)
 * - JARVIS_MEMORY_TOKEN_BUDGET: token limit (default: 1000)
 * - JARVIS_MAX_MEMORIES: entry limit (default: 10)
 */
export function getJarvisConfig(): JarvisConfig {
  return {
    enableMemoryLoading: process.env.JARVIS_ENABLE_MEMORY === 'true',
    memoryTokenBudget: parseInt(process.env.JARVIS_MEMORY_TOKEN_BUDGET || '1000', 10),
    maxMemories: parseInt(process.env.JARVIS_MAX_MEMORIES || '10', 10),
  };
}

// Singleton for convenience
export const jarvisConfig = getJarvisConfig();
```

Why: Feature flag allows disabling memory loading if issues arise, satisfying success criterion 4.
  </action>
  <verify>
TypeScript compiles:
```bash
npx tsc --noEmit
```
  </verify>
  <done>
Feature flag `jarvisConfig.enableMemoryLoading` controls memory loading, defaults to false for safe rollout.
  </done>
</task>

<task type="auto">
  <name>Task 2: Enhance system prompt to include memory context</name>
  <files>src/lib/jarvis/intelligence/systemPrompt.ts</files>
  <action>
Modify `src/lib/jarvis/intelligence/systemPrompt.ts`:

1. Update `SystemPromptContext` interface to include memory context:
```typescript
export interface SystemPromptContext {
  currentTime: Date;
  userName?: string;
  keyFacts?: string[];
  /** Pre-formatted memory context from database (Phase 8) */
  memoryContext?: string;
}
```

2. Modify `buildSystemPrompt()` to inject memory context:

In the CURRENT CONTEXT section, after key facts, add:
```typescript
// Add memory context if provided (from database)
if (context.memoryContext) {
  contextParts.push(`\n${context.memoryContext}`);
}
```

3. Add a section about referencing memories naturally (after CONVERSATION STYLE):
```typescript
// Add memory reference guidance when memory is loaded
if (context.memoryContext) {
  sections.push(`MEMORY CONTEXT:
- You have persistent memory of past conversations
- Reference previous facts naturally: "Your therapy is at 3pm" not "According to my records..."
- For preferences, just act on them without calling out: use bullet points if that's their preference
- When corrected about a memory: acknowledge and note the update ("Got it, Wednesdays now")
- For stale info, hedge naturally: "Last I knew, you were working on the Q2 budget"
- Surface pending tasks at session start: "Quick reminder: you wanted to follow up on that invoice"`);
}
```

This enhances the prompt only when memories are loaded, keeping v1 behavior unchanged when memory is disabled.
  </action>
  <verify>
TypeScript compiles:
```bash
npx tsc --noEmit
```
  </verify>
  <done>
`buildSystemPrompt()` accepts optional `memoryContext` parameter and injects it with natural reference guidance.
  </done>
</task>

<task type="auto">
  <name>Task 3: Load memories in chat API route</name>
  <files>src/app/api/jarvis/chat/route.ts</files>
  <action>
Modify `src/app/api/jarvis/chat/route.ts` to load memories:

1. Add imports at top:
```typescript
import { getJarvisConfig } from '@/lib/jarvis/config';
import { retrieveMemories, formatMemoriesForPrompt } from '@/lib/jarvis/memory';
```

2. Inside the `POST` handler, before calling Claude, load memories:

```typescript
// Load memory context if enabled
let memoryContext = '';
const config = getJarvisConfig();

if (config.enableMemoryLoading) {
  try {
    const memories = await retrieveMemories({
      maxTokens: config.memoryTokenBudget,
      maxEntries: config.maxMemories,
    });
    memoryContext = formatMemoriesForPrompt(memories);
    console.log(`[Chat] Loaded ${memories.entries.length} memories (${memories.totalTokens} tokens)`);
  } catch (error) {
    console.error('[Chat] Memory loading failed, continuing without:', error);
    // Don't fail the request, just proceed without memories
  }
}
```

3. Modify the system prompt passed to Claude to include memory context:

The current code passes `systemPrompt` directly. Instead:
- If `memoryContext` is present, append it to the systemPrompt
- Format: `${systemPrompt}\n\n${memoryContext}`

Actually, looking at the flow, the systemPrompt is built client-side in VoicePipeline.ts. We have two options:
A) Build system prompt server-side (cleaner, memory stays server-side)
B) Pass memory context to client and let it build (exposes memories to network)

Go with Option A: The server should build the full system prompt. Modify to:

```typescript
// Build system prompt server-side with memory context
import { buildSystemPrompt } from '@/lib/jarvis/intelligence/systemPrompt';

// In the request handling:
const fullSystemPrompt = buildSystemPrompt({
  currentTime: new Date(),
  memoryContext: memoryContext || undefined,
});

// Use fullSystemPrompt OR merge with client-provided systemPrompt
// If client sends basic prompt, enhance it; if client sends full prompt, use that
const effectiveSystemPrompt = memoryContext
  ? `${systemPrompt}\n\n${memoryContext}`
  : systemPrompt;
```

Use the simpler merge approach to avoid breaking existing behavior.
  </action>
  <verify>
TypeScript compiles:
```bash
npx tsc --noEmit
```
  </verify>
  <done>
Chat API loads memories from database when `JARVIS_ENABLE_MEMORY=true` and appends to system prompt.
  </done>
</task>

</tasks>

<verification>
1. TypeScript compiles: `npx tsc --noEmit`
2. Feature flag works: Set `JARVIS_ENABLE_MEMORY=true` in .env.local
3. Backward compatible: Without flag, behavior identical to v1
4. Memory appears in prompt: Console log shows "Loaded X memories"
</verification>

<success_criteria>
- Feature flag `JARVIS_ENABLE_MEMORY` controls memory loading (default: off)
- When enabled, memories are fetched from database at each chat request
- Memory context injected into system prompt in human-readable format
- Claude receives guidance on how to reference memories naturally
- Errors in memory loading are caught and logged, don't break chat
- v1 features work unchanged when flag is off
</success_criteria>

<output>
After completion, create `jarvis/.planning/phases/08-memory-loading-integration/08-02-SUMMARY.md`
</output>
