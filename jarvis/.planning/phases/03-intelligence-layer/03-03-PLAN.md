---
phase: 03-intelligence-layer
plan: 03
type: execute
wave: 2
depends_on: ["03-01", "03-02"]
files_modified:
  - src/lib/jarvis/intelligence/systemPrompt.ts
  - src/lib/jarvis/intelligence/tools.ts
  - src/lib/jarvis/voice/VoicePipeline.ts
  - src/app/api/jarvis/chat/route.ts
autonomous: true

must_haves:
  truths:
    - "User speaks and receives intelligent (not echo) responses"
    - "Jarvis maintains omnipresent guide personality (calm, knowing, not butler)"
    - "Jarvis knows current time and references it naturally"
    - "User can reference previous conversation ('What about that?') and Jarvis understands"
    - "Tool definitions exist but handlers acknowledge they're not yet implemented"
  artifacts:
    - path: "src/lib/jarvis/intelligence/systemPrompt.ts"
      provides: "Omnipresent guide personality prompt"
      exports: ["buildSystemPrompt"]
      min_lines: 40
    - path: "src/lib/jarvis/intelligence/tools.ts"
      provides: "Notion tool definitions for future Phase 4"
      exports: ["notionTools", "handleToolNotImplemented"]
      min_lines: 30
  key_links:
    - from: "src/lib/jarvis/voice/VoicePipeline.ts"
      to: "src/lib/jarvis/intelligence/ClaudeClient.ts"
      via: "responseGenerator calls claudeClient.chat"
      pattern: "ClaudeClient|claudeClient\\.chat"
    - from: "src/lib/jarvis/voice/VoicePipeline.ts"
      to: "src/lib/jarvis/intelligence/ConversationManager.ts"
      via: "builds context from conversationManager"
      pattern: "ConversationManager|conversationManager\\.(addMessage|getContext)"
    - from: "src/lib/jarvis/voice/VoicePipeline.ts"
      to: "src/lib/jarvis/intelligence/systemPrompt.ts"
      via: "generates system prompt with current time"
      pattern: "buildSystemPrompt"
---

<objective>
Wire Claude intelligence into VoicePipeline with guide personality and tool definitions.

Purpose: Transform Jarvis from echo mode to intelligent conversational partner. The system prompt establishes the omnipresent guide personality. Tool definitions prepare for Phase 4 Notion integration.

Output: Working end-to-end voice conversation with Claude, proper personality, time awareness, and multi-turn context.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@jarvis/.planning/PROJECT.md
@jarvis/.planning/ROADMAP.md
@jarvis/.planning/STATE.md
@jarvis/.planning/phases/03-intelligence-layer/03-RESEARCH.md
@jarvis/.planning/phases/03-intelligence-layer/03-CONTEXT.md

# Prior plan outputs (from 03-01 and 03-02)
@jarvis/.planning/phases/03-intelligence-layer/03-01-SUMMARY.md
@jarvis/.planning/phases/03-intelligence-layer/03-02-SUMMARY.md

# Files to update
@src/lib/jarvis/voice/VoicePipeline.ts
@src/app/api/jarvis/chat/route.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create system prompt for omnipresent guide personality</name>
  <files>src/lib/jarvis/intelligence/systemPrompt.ts</files>
  <action>
Create the system prompt builder. Match pattern from 03-RESEARCH.md but refine for CONTEXT.md decisions.

Interface:
```typescript
interface SystemPromptContext {
  currentTime: Date;
  userName?: string;
  keyFacts?: string[];
}

export function buildSystemPrompt(context: SystemPromptContext): string;
```

Implementation:
1. Format currentTime as readable string: "Friday, 3:45 PM"
2. Build prompt with these sections:

PERSONALITY:
- Calm, knowing, always present - like a wise friend who sees the bigger picture
- Warm and direct, never formal or servile (NOT a butler, NOT British)
- Brief for simple asks, detailed when complexity warrants
- Proactively helpful - anticipate needs, suggest next steps

CURRENT CONTEXT:
- Current time from context.currentTime
- Key facts if provided (from cross-session memory)

CONVERSATION STYLE:
- Speak naturally, as if thinking alongside the user
- When uncertain: admit directly, ask clarifying questions, then offer best effort
- Reference previous conversation when relevant
- Keep responses conversational - this is voice, not text

CAPABILITIES:
- Currently: Natural conversation, time awareness, remembering context
- Coming soon: Notion integration for tasks, projects, bills
- When asked about unimplemented features: acknowledge, note for development

VOICE INTERFACE:
- Prefer shorter sentences over long explanations
- Avoid lists and formatting that doesn't translate to speech
- Use contractions, natural rhythm

3. Insert userName where appropriate (default to "you" if not provided)
4. Insert keyFacts as bullet list under CURRENT CONTEXT if provided

Export the function.
  </action>
  <verify>
- File exists at correct path
- TypeScript compiles: `npx tsc --noEmit src/lib/jarvis/intelligence/systemPrompt.ts`
- buildSystemPrompt function exported
  </verify>
  <done>System prompt establishes omnipresent guide personality with time awareness</done>
</task>

<task type="auto">
  <name>Task 2: Create tool definitions for future Notion operations</name>
  <files>src/lib/jarvis/intelligence/tools.ts</files>
  <action>
Define tool schemas for Notion operations. Handlers acknowledge capability gap gracefully.

Match pattern from 03-RESEARCH.md:

```typescript
export const notionTools = [
  {
    name: 'create_task',
    description: 'Create a new task in the user\'s Notion inbox...',
    input_schema: { ... }
  },
  {
    name: 'query_tasks',
    description: 'Search and retrieve tasks from Notion...',
    input_schema: { ... }
  },
  {
    name: 'query_bills',
    description: 'Check upcoming bills and payment status...',
    input_schema: { ... }
  }
];

export function handleToolNotImplemented(toolName: string, input: unknown): string {
  // Return message acknowledging capability coming soon
  // Log request for roadmap (console.log for now)
}
```

Tools to define (schemas only, no real handlers):
1. create_task - title, optional due_date, optional priority
2. query_tasks - filter (today/this_week/overdue/all), status
3. query_bills - timeframe (this_week/this_month/overdue)
4. update_task_status - task_id, new_status
5. mark_bill_paid - bill_id

handleToolNotImplemented should:
- Log the request (for future roadmap)
- Return friendly message: "I understand you want to [action]. This capability is coming soon."

Export both notionTools and handleToolNotImplemented.
  </action>
  <verify>
- File exists at correct path
- TypeScript compiles: `npx tsc --noEmit src/lib/jarvis/intelligence/tools.ts`
- notionTools array and handleToolNotImplemented function exported
  </verify>
  <done>Tool definitions ready for Phase 4 with graceful fallback for unimplemented calls</done>
</task>

<task type="auto">
  <name>Task 3: Wire intelligence into VoicePipeline</name>
  <files>src/lib/jarvis/voice/VoicePipeline.ts, src/app/api/jarvis/chat/route.ts</files>
  <action>
Update VoicePipeline to use Claude instead of echo. Update chat route to include tools.

**VoicePipeline changes:**

1. Import new modules:
```typescript
import { ClaudeClient } from '../intelligence/ClaudeClient';
import { ConversationManager } from '../intelligence/ConversationManager';
import { MemoryStore } from '../intelligence/MemoryStore';
import { buildSystemPrompt } from '../intelligence/systemPrompt';
```

2. Add to constructor:
```typescript
private claudeClient: ClaudeClient;
private conversationManager: ConversationManager;
private memoryStore: MemoryStore;
```

3. Initialize in constructor:
```typescript
this.memoryStore = new MemoryStore();
this.conversationManager = new ConversationManager(this.memoryStore);
this.claudeClient = new ClaudeClient();
```

4. Replace defaultResponseGenerator with intelligent one:
```typescript
private async generateIntelligentResponse(transcript: string): Promise<string> {
  return new Promise((resolve, reject) => {
    // Add user message to context
    this.conversationManager.addMessage({ role: 'user', content: transcript });

    // Build context
    const messages = this.conversationManager.getContextMessages();
    const systemPrompt = buildSystemPrompt({
      currentTime: new Date(),
      keyFacts: this.conversationManager.getKeyFacts()
    });

    let fullResponse = '';

    this.claudeClient.chat(messages, systemPrompt, {
      onToken: (text) => {
        fullResponse += text;
        // Could stream to TTS here for lower latency (future optimization)
      },
      onComplete: (text) => {
        this.conversationManager.addMessage({ role: 'assistant', content: text });
        resolve(text);
      },
      onError: (error) => {
        reject(error);
      }
    });
  });
}
```

5. Update processTranscript to use generateIntelligentResponse:
```typescript
const response = await this.generateIntelligentResponse(transcript);
```

6. Update cancel() to also abort Claude client:
```typescript
this.claudeClient.abort();
```

**Chat route changes (src/app/api/jarvis/chat/route.ts):**

1. Import tools:
```typescript
import { notionTools, handleToolNotImplemented } from '@/lib/jarvis/intelligence/tools';
```

2. Add tools to stream call:
```typescript
const response = anthropic.messages.stream({
  model: 'claude-haiku-4-5',
  max_tokens: 1024,
  system: systemPrompt,
  messages,
  tools: notionTools,  // Add this
});
```

3. Handle tool_use events in stream:
```typescript
if (event.type === 'content_block_start' && event.content_block.type === 'tool_use') {
  // Tool call detected - will be handled in stop event
}
if (event.type === 'message_stop') {
  // Check if response contains tool_use, call handleToolNotImplemented
  // For Phase 3, just acknowledge the tool call in the response
}
```

Note: Full tool handling with actual Notion calls comes in Phase 4. For now, if Claude calls a tool, we acknowledge and continue.
  </action>
  <verify>
- Both files updated
- TypeScript compiles: `npx tsc --noEmit`
- VoicePipeline imports intelligence modules
- Chat route includes tools array
  </verify>
  <done>VoicePipeline uses Claude for intelligent responses with context management</done>
</task>

</tasks>

<verification>
1. Start dev server: `npm run dev`
2. Open http://localhost:3000/jarvis
3. Press push-to-talk, say "Hello, what time is it?"
4. Verify:
   - Jarvis responds with current time (not echo)
   - Personality is warm and direct (not butler-like)
   - Response is conversational (not list-formatted)
5. Test multi-turn:
   - Say "My name is Jonathan"
   - Then say "What's my name?"
   - Jarvis should remember and respond correctly
6. Test time awareness:
   - Ask "Is it a good time for a break?"
   - Jarvis should reference actual current time
7. Test tool acknowledgment:
   - Say "Add a task to call mom"
   - Jarvis should acknowledge capability is coming soon (not crash)
</verification>

<success_criteria>
- User speaks and receives intelligent responses (not echo)
- Jarvis maintains omnipresent guide personality throughout
- Jarvis knows and references current time naturally
- Multi-turn conversation works (Jarvis remembers prior statements)
- Tool calls are handled gracefully with "coming soon" acknowledgment
- Orb animates correctly through idle -> listening -> thinking -> speaking
</success_criteria>

<output>
After completion, create `jarvis/.planning/phases/03-intelligence-layer/03-03-SUMMARY.md`
</output>
