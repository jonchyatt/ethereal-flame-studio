---
phase: 03-intelligence-layer
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/app/api/jarvis/chat/route.ts
  - src/lib/jarvis/intelligence/ClaudeClient.ts
  - package.json
autonomous: true

must_haves:
  truths:
    - "Claude API calls are proxied through server (API key never exposed to browser)"
    - "Streaming tokens arrive in browser as SSE events"
    - "Response text accumulates correctly from token stream"
  artifacts:
    - path: "src/app/api/jarvis/chat/route.ts"
      provides: "SSE streaming proxy to Claude API"
      exports: ["POST"]
      min_lines: 40
    - path: "src/lib/jarvis/intelligence/ClaudeClient.ts"
      provides: "Browser client for chat API"
      exports: ["ClaudeClient"]
      min_lines: 50
  key_links:
    - from: "src/lib/jarvis/intelligence/ClaudeClient.ts"
      to: "/api/jarvis/chat"
      via: "fetch with SSE parsing"
      pattern: "fetch.*api/jarvis/chat"
    - from: "src/app/api/jarvis/chat/route.ts"
      to: "anthropic"
      via: "Anthropic SDK streaming"
      pattern: "anthropic\\.messages\\.stream"
---

<objective>
Create Claude API integration with SSE streaming for low-latency conversational responses.

Purpose: Enable Jarvis to call Claude for intelligent responses instead of echo mode. Streaming ensures first tokens arrive quickly for conversational feel.

Output: Working Claude API route and browser client that can send messages and receive streaming responses.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@jarvis/.planning/PROJECT.md
@jarvis/.planning/ROADMAP.md
@jarvis/.planning/STATE.md
@jarvis/.planning/phases/03-intelligence-layer/03-RESEARCH.md

# Existing voice pipeline (will integrate in 03-03)
@src/lib/jarvis/voice/VoicePipeline.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install Anthropic SDK</name>
  <files>package.json</files>
  <action>
Install the Anthropic TypeScript SDK:

```bash
npm install @anthropic-ai/sdk
```

Verify ANTHROPIC_API_KEY is set in environment (should be in .env.local, NOT prefixed with NEXT_PUBLIC_).

Do NOT commit or log the API key.
  </action>
  <verify>
- `npm ls @anthropic-ai/sdk` shows package installed
- `grep ANTHROPIC_API_KEY .env.local` confirms key exists (without revealing value)
  </verify>
  <done>Anthropic SDK installed and API key configured in environment</done>
</task>

<task type="auto">
  <name>Task 2: Create Claude API streaming route</name>
  <files>src/app/api/jarvis/chat/route.ts</files>
  <action>
Create POST endpoint that proxies to Claude API with SSE streaming. Match the pattern from 03-RESEARCH.md.

Request body:
```typescript
{
  messages: Array<{ role: 'user' | 'assistant'; content: string }>;
  systemPrompt: string;
}
```

Implementation:
1. Import and instantiate Anthropic client (reads ANTHROPIC_API_KEY from env automatically)
2. Use `anthropic.messages.stream()` with:
   - model: 'claude-haiku-4-5' (fast TTFT for voice)
   - max_tokens: 1024 (sufficient for conversational responses)
   - system: from request body
   - messages: from request body
3. Create ReadableStream that:
   - Iterates over stream events
   - For `content_block_delta` with `text_delta`, send SSE: `data: {"type":"text","text":"..."}\n\n`
   - On completion, send: `data: {"type":"done"}\n\n`
   - Close controller
4. Return Response with SSE headers:
   - Content-Type: text/event-stream
   - Cache-Control: no-cache
   - Connection: keep-alive

Handle errors gracefully - return 500 with error message if Claude API fails.

Important: Do NOT include tools in this plan - they come in 03-03.
  </action>
  <verify>
- File exists at correct path
- TypeScript compiles without errors: `npx tsc --noEmit src/app/api/jarvis/chat/route.ts`
- Route exports POST function
  </verify>
  <done>Claude API route streams responses via SSE</done>
</task>

<task type="auto">
  <name>Task 3: Create browser ClaudeClient</name>
  <files>src/lib/jarvis/intelligence/ClaudeClient.ts</files>
  <action>
Create browser-side client for the chat API. Match pattern from 03-RESEARCH.md.

Interface:
```typescript
interface ChatCallbacks {
  onToken: (text: string) => void;
  onComplete: (fullText: string) => void;
  onError: (error: Error) => void;
}

export class ClaudeClient {
  private abortController: AbortController | null = null;

  async chat(
    messages: Array<{ role: 'user' | 'assistant'; content: string }>,
    systemPrompt: string,
    callbacks: ChatCallbacks
  ): Promise<void>;

  abort(): void;
}
```

Implementation:
1. Store AbortController for cancellation support
2. fetch('/api/jarvis/chat', { method: 'POST', ... })
3. Parse SSE response:
   - Get reader from response.body
   - Decode chunks with TextDecoder({ stream: true })
   - Split on newlines, parse lines starting with 'data: '
   - Call onToken for text events, onComplete for done
4. Handle abort gracefully (don't call onError for AbortError)
5. Call onError for non-abort errors

Export the ClaudeClient class for use by other modules.
  </action>
  <verify>
- File exists at correct path
- TypeScript compiles: `npx tsc --noEmit src/lib/jarvis/intelligence/ClaudeClient.ts`
- ClaudeClient class is exported
  </verify>
  <done>Browser client can call chat API and receive streaming tokens</done>
</task>

</tasks>

<verification>
1. Start dev server: `npm run dev`
2. Create a test script or use curl to verify the API:
```bash
curl -X POST http://localhost:3000/api/jarvis/chat \
  -H "Content-Type: application/json" \
  -d '{"messages":[{"role":"user","content":"Say hello in one word"}],"systemPrompt":"Be brief."}' \
  --no-buffer
```
3. Verify SSE events stream to terminal
4. Check for `data: {"type":"done"}` at end
</verification>

<success_criteria>
- POST /api/jarvis/chat accepts messages and systemPrompt
- Response streams SSE events with text tokens
- ClaudeClient parses stream and invokes callbacks
- No API key exposure in browser (only server-side)
- TypeScript compiles without errors
</success_criteria>

<output>
After completion, create `jarvis/.planning/phases/03-intelligence-layer/03-01-SUMMARY.md`
</output>
